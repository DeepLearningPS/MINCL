在丹阳的模型上，测试WN18RR


tmux test301开始

 CUDA_VISIBLE_DEVICES=3 python -m torch.distributed.launch --nproc_per_node=1 --master_port 29301 run_wn18rr_no_dgi.py --dataset WN18RR --optimizer adamw --use_test 1 --test_name optimizer_adamw  ，默认使用的是余弦'CosineAnnealingLR'，所以比较GAT版本的'CosineAnnealingLR'即可
结束


 目前模型使用动态学习率和AdamW效果不好。现在使用丹阳的原始的策略：adam

  CUDA_VISIBLE_DEVICES=3 python -m torch.distributed.launch --nproc_per_node=1 --master_port 29302 run_wn18rr_no_dgi.py --dataset WN18RR --optimizer adam --change_lr 0 --use_test 1 --test_name optimizer_adam_change_lr_false

结束，效果依旧不好


WN18RR数据集上的测试：

CUDA_VISIBLE_DEVICES=1 python -m torch.distributed.launch run_wn18rr_no_dgi.py
test results: MRR is 0.46656, MR is 5395.11838, Hits@10 is0.52585, Hits@3 is 0.48086, Hit@1 is 0.43634

test results: MRR is 0.0237, MR is 13473.65747, Hits@10 is0.04116, Hits@3 is 0.02345, Hit@1 is 0.0142，效果有问题

WN18RR上的数据集,默认配置有问题

在WN18RR上，我们使用新的参数配置跑一下试试：丹阳的CMGAT_v21。目前还在调试，计算所跑

CUDA_VISIBLE_DEVICES=1 python -m torch.distributed.launch run_wn18rr_no_dgi.py
结束

Epoch 701 
MRR：0.47281
MR： 3662.10689 
Hit@1： 0.43762
Hits@3： 0.4858
Hits@10： 0.53845

基本上达到了实验要求，总体差了1%

WN18RR上的数据集效果达到了实验要求?

看看在改造之后的代码上的效果：CMGAT

CUDA_VISIBLE_DEVICES=1 python -m torch.distributed.launch --nproc_per_node=1 --master_port 29203 run_wn18rr_no_dgi.py --dataset WN18RR --optimizer adam --change_lr 0 --use_test 1 --test_name new_optimizer_adam_change_lr_false

结束


测试:
Epoch:443 
Test_mrr: 0.46796
Test_mr: 3767.63641
Test_hit1: 0.43188
Test_hit3: 0.48245
Test_hit10: 0.53494

结论，CMGAT基本上达到了丹阳的源代码要求


试试对比学习：

CUDA_VISIBLE_DEVICES=2,3 torchrun --rdzv_backend c10d --rdzv_endpoint localhost:0 --nnodes 1 --nproc_per_node 2 --rdzv_id 2 run_wn18rr_no_dgi.py --dataset WN18RR --loss_function contrastive_loss --use_test 1 --test_name ChangeLR-UnitVec-BN-CLoss-part-sample-Tem0.2  --score_func conve --subgraph_loss_rate 0 --sample_mod part --temperature 0.2 --stop_num 1000 --change_lr 0 --optimizer adam 

tmux a -t wn18rr
ssh scx6266@paraai-n32-h-01-agent-15
conda activate GNN
module load bazel/3.7.2
module load compilers/cuda/11.3
module load compilers/gcc/9.3.0
module load nccl/2.17.1-1_cuda11.3
cd /home/bingxing2/home/scx6266/GNN/new_达到实验结果的CMGAT
export LD_PRELOAD=$LD_PRELOAD:/home/bingxing2/home/scx6266/.conda/envs/geodiff/lib/python3.8/site-packages/sklearn/__check_build/../../scikit_learn.libs/libgomp-d22c30c5.so.1.0.0


提升效果很小。使用动态学习率 + 连续10epoch没有上升则温度系数增加0.05

CUDA_VISIBLE_DEVICES=1 torchrun --rdzv_backend c10d --rdzv_endpoint localhost:0 --nnodes 1 --nproc_per_node 1 --rdzv_id 1 run_wn18rr_no_dgi.py --dataset WN18RR --loss_function contrastive_loss --use_test 1 --test_name ChangeLR-UnitVec-BN-CLoss-part-sample-Tem0.05  --score_func conve --subgraph_loss_rate 0 --sample_mod part --temperature 0.05 --stop_num 100 --change_lr 1 --optimizer adam --save_path LP_ChangeLR-UnitVec-BN-CLoss-part-sample-Tem0.2_notext_conve_contrastive_loss_WN18RR_CLcmgat_06_06_2023_01_16_16

效果有提升，小的温度系数有利于提高模型性能.但可能不适合开始。 

温度系数需要随着训练次数增加而变化，是从大到小变化, 还是从小到大变化，或者像余弦函数一样周期变化







 
160上

tmux a -t wn18rr + 静态学习率 + tmux a -t db8k 在跑

CUDA_VISIBLE_DEVICES=3 torchrun --rdzv_backend c10d --rdzv_endpoint localhost:0 --nnodes 1 --nproc_per_node 1 --rdzv_id 1 run_db8k-28_no_dgi.py --dataset DB8k-28 --loss_function contrastive_loss --use_test 1 --test_name ChangeLR-UnitVec-BN-CLoss-part-sample-Tem1.0  --score_func conve --subgraph_loss_rate 0 --sample_mod part --temperature 1.0 --stop_num 100 --change_lr 0 --optimizer adam 



2023-06-13 17:15:44,810 - run_db8k-28_no_dgi.py - [INFO] - Early Stopping!!
2023-06-13 17:15:44,810 - run_db8k-28_no_dgi.py - [INFO] - best_epoch: 325
2023-06-13 17:15:44,810 - run_db8k-28_no_dgi.py - [INFO] - best_lr: 0.0010000000
2023-06-13 17:15:44,810 - run_db8k-28_no_dgi.py - [INFO] - best_mrr: 0.70367
2023-06-13 17:15:44,811 - run_db8k-28_no_dgi.py - [INFO] - best_mr: 34.10468
2023-06-13 17:15:44,811 - run_db8k-28_no_dgi.py - [INFO] - best_hit1: 0.66029
2023-06-13 17:15:44,811 - run_db8k-28_no_dgi.py - [INFO] - best_hit3: 0.71895
2023-06-13 17:15:44,811 - run_db8k-28_no_dgi.py - [INFO] - best_hit10: 0.78824
2023-06-13 17:15:44,811 - run_db8k-28_no_dgi.py - [INFO] - 


state['optimizer']: dict_keys(['state', 'param_groups'])
2023-06-13 17:15:51,235 - run_db8k-28_no_dgi.py - [INFO] - 测试:
2023-06-13 17:15:51,235 - run_db8k-28_no_dgi.py - [INFO] - Test_mrr: 0.70545
2023-06-13 17:15:51,235 - run_db8k-28_no_dgi.py - [INFO] - Test_mr: 30.41964
2023-06-13 17:15:51,235 - run_db8k-28_no_dgi.py - [INFO] - Test_hit1: 0.66057
2023-06-13 17:15:51,235 - run_db8k-28_no_dgi.py - [INFO] - Test_hit3: 0.72040
2023-06-13 17:15:51,235 - run_db8k-28_no_dgi.py - [INFO] - Test_hit10: 0.79395
2023-06-13 17:15:51,235 - run_db8k-28_no_dgi.py - [INFO] - 程序终止时间:Tue Jun 13 17:15:51 2023
file name: LP_ChangeLR-UnitVec-BN-CLoss-part-sample-Tem1.0_notext_conve_contrastive_loss_DB8k-28_CLcmgat_11_06_2023_19_46_29






从头跑，温度系数从1.0开始 + 动态学习率

CUDA_VISIBLE_DEVICES=1 torchrun --rdzv_backend c10d --rdzv_endpoint localhost:0 --nnodes 1 --nproc_per_node 1 --rdzv_id 1 run_db8k-28_no_dgi.py --dataset DB8k-28 --loss_function contrastive_loss --use_test 1 --test_name ChangeLR-UnitVec-BN-CLoss-part-sample-Tem1.0  --score_func conve --subgraph_loss_rate 0 --sample_mod part --temperature 1.0 --stop_num 100 --change_lr 1 --optimizer adam


没有泄露的结果

2023-06-28 18:20:20,887 - run_db8k-28_no_dgi.py - [INFO] - best_epoch: 736
2023-06-28 18:20:20,887 - run_db8k-28_no_dgi.py - [INFO] - best_lr: 0.0010000000
2023-06-28 18:20:20,888 - run_db8k-28_no_dgi.py - [INFO] - best_mrr: 0.50761
2023-06-28 18:20:20,888 - run_db8k-28_no_dgi.py - [INFO] - best_mr: 36.01063
2023-06-28 18:20:20,888 - run_db8k-28_no_dgi.py - [INFO] - best_hit1: 0.40035
2023-06-28 18:20:20,888 - run_db8k-28_no_dgi.py - [INFO] - best_hit3: 0.56491
2023-06-28 18:20:20,888 - run_db8k-28_no_dgi.py - [INFO] - best_hit10: 0.70730
2023-06-28 18:20:20,888 - run_db8k-28_no_dgi.py - [INFO] - 


state['optimizer']: dict_keys(['state', 'param_groups'])
2023-06-28 18:20:25,444 - run_db8k-28_no_dgi.py - [INFO] - 测试:
2023-06-28 18:20:25,445 - run_db8k-28_no_dgi.py - [INFO] - Test_mrr: 0.50949
2023-06-28 18:20:25,445 - run_db8k-28_no_dgi.py - [INFO] - Test_mr: 33.64484
2023-06-28 18:20:25,445 - run_db8k-28_no_dgi.py - [INFO] - Test_hit1: 0.39941
2023-06-28 18:20:25,445 - run_db8k-28_no_dgi.py - [INFO] - Test_hit3: 0.56609
2023-06-28 18:20:25,445 - run_db8k-28_no_dgi.py - [INFO] - Test_hit10: 0.71759
2023-06-28 18:20:25,445 - run_db8k-28_no_dgi.py - [INFO] - 程序终止时间:Wed Jun 28 18:20:25 2023
file name: LP_ChangeLR-UnitVec-BN-CLoss-part-sample-Tem1.0_notext_conve_contrastive_loss_DB8k-28_CLcmgat_24_06_2023_22_32_08