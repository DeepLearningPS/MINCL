在丹阳的模型上，测试WN18RR


tmux test301开始

 CUDA_VISIBLE_DEVICES=3 python -m torch.distributed.launch --nproc_per_node=1 --master_port 29301 run_wn18rr_no_dgi.py --dataset WN18RR --optimizer adamw --use_test 1 --test_name optimizer_adamw  ，默认使用的是余弦'CosineAnnealingLR'，所以比较GAT版本的'CosineAnnealingLR'即可
结束


 目前模型使用动态学习率和AdamW效果不好。现在使用丹阳的原始的策略：adam

  CUDA_VISIBLE_DEVICES=3 python -m torch.distributed.launch --nproc_per_node=1 --master_port 29302 run_wn18rr_no_dgi.py --dataset WN18RR --optimizer adam --change_lr 0 --use_test 1 --test_name optimizer_adam_change_lr_false

结束，效果依旧不好


WN18RR数据集上的测试：

CUDA_VISIBLE_DEVICES=1 python -m torch.distributed.launch run_wn18rr_no_dgi.py
test results: MRR is 0.46656, MR is 5395.11838, Hits@10 is0.52585, Hits@3 is 0.48086, Hit@1 is 0.43634

test results: MRR is 0.0237, MR is 13473.65747, Hits@10 is0.04116, Hits@3 is 0.02345, Hit@1 is 0.0142，效果有问题

WN18RR上的数据集,默认配置有问题

在WN18RR上，我们使用新的参数配置跑一下试试：丹阳的CMGAT_v21。目前还在调试，计算所跑

CUDA_VISIBLE_DEVICES=1 python -m torch.distributed.launch run_wn18rr_no_dgi.py
结束

Epoch 701 
MRR：0.47281
MR： 3662.10689 
Hit@1： 0.43762
Hits@3： 0.4858
Hits@10： 0.53845

基本上达到了实验要求，总体差了1%

WN18RR上的数据集效果达到了实验要求?

看看在改造之后的代码上的效果：CMGAT

CUDA_VISIBLE_DEVICES=1 python -m torch.distributed.launch --nproc_per_node=1 --master_port 29203 run_wn18rr_no_dgi.py --dataset WN18RR --optimizer adam --change_lr 0 --use_test 1 --test_name new_optimizer_adam_change_lr_false

结束


测试:
Epoch:443 
Test_mrr: 0.46796
Test_mr: 3767.63641
Test_hit1: 0.43188
Test_hit3: 0.48245
Test_hit10: 0.53494

结论，CMGAT基本上达到了丹阳的源代码要求


试试对比学习：

CUDA_VISIBLE_DEVICES=2,3 torchrun --rdzv_backend c10d --rdzv_endpoint localhost:0 --nnodes 1 --nproc_per_node 2 --rdzv_id 2 run_wn18rr_no_dgi.py --dataset WN18RR --loss_function contrastive_loss --use_test 1 --test_name ChangeLR-UnitVec-BN-CLoss-part-sample-Tem0.2  --score_func conve --subgraph_loss_rate 0 --sample_mod part --temperature 0.2 --stop_num 1000 --change_lr 0 --optimizer adam 

tmux a -t wn18rr
ssh scx6266@paraai-n32-h-01-agent-15
conda activate GNN
module load bazel/3.7.2
module load compilers/cuda/11.3
module load compilers/gcc/9.3.0
module load nccl/2.17.1-1_cuda11.3
cd /home/bingxing2/home/scx6266/GNN/new_达到实验结果的CMGAT
export LD_PRELOAD=$LD_PRELOAD:/home/bingxing2/home/scx6266/.conda/envs/geodiff/lib/python3.8/site-packages/sklearn/__check_build/../../scikit_learn.libs/libgomp-d22c30c5.so.1.0.0


提升效果很小。使用动态学习率 + 连续10epoch没有上升则温度系数增加0.05

CUDA_VISIBLE_DEVICES=1 torchrun --rdzv_backend c10d --rdzv_endpoint localhost:0 --nnodes 1 --nproc_per_node 1 --rdzv_id 1 run_wn18rr_no_dgi.py --dataset WN18RR --loss_function contrastive_loss --use_test 1 --test_name ChangeLR-UnitVec-BN-CLoss-part-sample-Tem0.05  --score_func conve --subgraph_loss_rate 0 --sample_mod part --temperature 0.05 --stop_num 100 --change_lr 1 --optimizer adam --save_path LP_ChangeLR-UnitVec-BN-CLoss-part-sample-Tem0.2_notext_conve_contrastive_loss_WN18RR_CLcmgat_06_06_2023_01_16_16

效果有提升，小的温度系数有利于提高模型性能.但可能不适合开始。 

温度系数需要随着训练次数增加而变化，是从大到小变化, 还是从小到大变化，或者像余弦函数一样周期变化



最终结果：

2023-06-07 08:11:55,336 - run_wn18rr_no_dgi.py - [INFO] - 测试:
2023-06-07 08:11:55,337 - run_wn18rr_no_dgi.py - [INFO] - Test_mrr: 0.50075
2023-06-07 08:11:55,337 - run_wn18rr_no_dgi.py - [INFO] - Test_mr: 4633.47320
2023-06-07 08:11:55,337 - run_wn18rr_no_dgi.py - [INFO] - Test_hit1: 0.47288
2023-06-07 08:11:55,337 - run_wn18rr_no_dgi.py - [INFO] - Test_hit3: 0.51404
2023-06-07 08:11:55,337 - run_wn18rr_no_dgi.py - [INFO] - Test_hit10: 0.55169
2023-06-07 08:11:55,337 - run_wn18rr_no_dgi.py - [INFO] - 程序终止时间:Wed Jun  7 08:11:55 2023
file name: LP_ChangeLR-UnitVec-BN-CLoss-part-sample-Tem0.05_notext_conve_contrastive_loss_WN18RR_CLcmgat_06_06_2023_23_29_12



从头跑，温度系数从1.0开始 + 动态学习率

CUDA_VISIBLE_DEVICES=1 torchrun --rdzv_backend c10d --rdzv_endpoint localhost:0 --nnodes 1 --nproc_per_node 1 --rdzv_id 1 run_wn18rr_no_dgi.py --dataset WN18RR --loss_function contrastive_loss --use_test 1 --test_name ChangeLR-UnitVec-BN-CLoss-part-sample-Tem1.0  --score_func conve --subgraph_loss_rate 0 --sample_mod part --temperature 1.0 --stop_num 100 --change_lr 1 --optimizer adam 


2023-06-08 07:46:56,632 - run_wn18rr_no_dgi.py - [INFO] - Early Stopping!!
2023-06-08 07:46:56,632 - run_wn18rr_no_dgi.py - [INFO] - best_epoch: 210
2023-06-08 07:46:56,633 - run_wn18rr_no_dgi.py - [INFO] - best_lr: 0.0008950775
2023-06-08 07:46:56,633 - run_wn18rr_no_dgi.py - [INFO] - best_mrr: 0.50195
2023-06-08 07:46:56,633 - run_wn18rr_no_dgi.py - [INFO] - best_mr: 4288.43804
2023-06-08 07:46:56,633 - run_wn18rr_no_dgi.py - [INFO] - best_hit1: 0.47676
2023-06-08 07:46:56,633 - run_wn18rr_no_dgi.py - [INFO] - best_hit3: 0.50906
2023-06-08 07:46:56,633 - run_wn18rr_no_dgi.py - [INFO] - best_hit10: 0.55142
2023-06-08 07:46:56,633 - run_wn18rr_no_dgi.py - [INFO] - 


state['optimizer']: dict_keys(['state', 'param_groups'])
2023-06-08 07:46:58,640 - run_wn18rr_no_dgi.py - [INFO] - 测试:
2023-06-08 07:46:58,640 - run_wn18rr_no_dgi.py - [INFO] - Test_mrr: 0.50509
2023-06-08 07:46:58,640 - run_wn18rr_no_dgi.py - [INFO] - Test_mr: 4106.26978
2023-06-08 07:46:58,641 - run_wn18rr_no_dgi.py - [INFO] - Test_hit1: 0.47878
2023-06-08 07:46:58,641 - run_wn18rr_no_dgi.py - [INFO] - Test_hit3: 0.51244
2023-06-08 07:46:58,641 - run_wn18rr_no_dgi.py - [INFO] - Test_hit10: 0.55440
2023-06-08 07:46:58,641 - run_wn18rr_no_dgi.py - [INFO] - 程序终止时间:Thu Jun  8 07:46:58 2023
file name: LP_ChangeLR-UnitVec-BN-CLoss-part-sample-Tem1.0_notext_conve_contrastive_loss_WN18RR_CLcmgat_07_06_2023_11_26_36







使用预训练的文本语义嵌入 tmux a -t wn18rr2：效果不好，探索一下原因，停了

CUDA_VISIBLE_DEVICES=1 torchrun --rdzv_backend c10d --rdzv_endpoint localhost:0 --nnodes 1 --nproc_per_node 1 --rdzv_id 1 run_wn18rr_no_dgi.py --dataset WN18RR --loss_function contrastive_loss --use_test 1 --test_name ChangeLR-UnitVec-BN-CLoss-part-sample-Tem1.0  --score_func conve --subgraph_loss_rate 0 --sample_mod part --temperature 1.0 --stop_num 100 --change_lr 1 --optimizer adam --use_pretrain 1



在160上跑

tmux a -t wn18rr + 静态学习率

CUDA_VISIBLE_DEVICES=2 torchrun --rdzv_backend c10d --rdzv_endpoint localhost:0 --nnodes 1 --nproc_per_node 1 --rdzv_id 1 run_wn18rr_no_dgi.py --dataset WN18RR --loss_function contrastive_loss --use_test 1 --test_name ChangeLR-UnitVec-BN-CLoss-part-sample-Tem1.0  --score_func conve --subgraph_loss_rate 0 --sample_mod part --temperature 1.0 --stop_num 100 --change_lr 0 --optimizer adam 


2023-06-09 10:56:58,862 - run_wn18rr_no_dgi.py - [INFO] - Early Stopping!!
2023-06-09 10:56:58,862 - run_wn18rr_no_dgi.py - [INFO] - best_epoch: 224
2023-06-09 10:56:58,862 - run_wn18rr_no_dgi.py - [INFO] - best_lr: 0.0010000000
2023-06-09 10:56:58,862 - run_wn18rr_no_dgi.py - [INFO] - best_mrr: 0.50365
2023-06-09 10:56:58,862 - run_wn18rr_no_dgi.py - [INFO] - best_mr: 4309.14140
2023-06-09 10:56:58,862 - run_wn18rr_no_dgi.py - [INFO] - best_hit1: 0.47693
2023-06-09 10:56:58,863 - run_wn18rr_no_dgi.py - [INFO] - best_hit3: 0.51236
2023-06-09 10:56:58,863 - run_wn18rr_no_dgi.py - [INFO] - best_hit10: 0.55422
2023-06-09 10:56:58,863 - run_wn18rr_no_dgi.py - [INFO] - 


state['optimizer']: dict_keys(['state', 'param_groups'])
2023-06-09 10:57:04,801 - run_wn18rr_no_dgi.py - [INFO] - 测试:
2023-06-09 10:57:04,804 - run_wn18rr_no_dgi.py - [INFO] - Test_mrr: 0.50531
2023-06-09 10:57:04,806 - run_wn18rr_no_dgi.py - [INFO] - Test_mr: 4422.89215
2023-06-09 10:57:04,807 - run_wn18rr_no_dgi.py - [INFO] - Test_hit1: 0.47878
2023-06-09 10:57:04,808 - run_wn18rr_no_dgi.py - [INFO] - Test_hit3: 0.51532
2023-06-09 10:57:04,810 - run_wn18rr_no_dgi.py - [INFO] - Test_hit10: 0.55504
2023-06-09 10:57:04,811 - run_wn18rr_no_dgi.py - [INFO] - 程序终止时间:Fri Jun  9 10:57:04 2023
file name: LP_ChangeLR-UnitVec-BN-CLoss-part-sample-Tem1.0_notext_conve_contrastive_loss_WN18RR_CLcmgat_08_06_2023_00_54_42


我们需要统计一下每一个节点的出入度



 tmux a -t wn18rr

CUDA_VISIBLE_DEVICES=2 torchrun --rdzv_backend c10d --rdzv_endpoint localhost:0 --nnodes 1 --nproc_per_node 1 --rdzv_id 1 run_wn18rr_no_dgi.py --dataset WN18RR --loss_function contrastive_loss --use_test 1 --test_name ChangeLR-UnitVec-BN-CLoss-part-sample-Tem1.0  --score_func conve --subgraph_loss_rate 0 --sample_mod part --temperature 1.0 --stop_num 1000 --change_lr 0 --optimizer adam 



2023-07-01 23:45:38,270 - run_wn18rr_no_dgi.py - [INFO] - best_epoch: 337
2023-07-01 23:45:38,270 - run_wn18rr_no_dgi.py - [INFO] - best_lr: 0.0010000000
2023-07-01 23:45:38,270 - run_wn18rr_no_dgi.py - [INFO] - best_mrr: 0.46145
2023-07-01 23:45:38,270 - run_wn18rr_no_dgi.py - [INFO] - best_mr: 4263.47862
2023-07-01 23:45:38,270 - run_wn18rr_no_dgi.py - [INFO] - best_hit1: 0.42119
2023-07-01 23:45:38,270 - run_wn18rr_no_dgi.py - [INFO] - best_hit3: 0.47958
2023-07-01 23:45:38,270 - run_wn18rr_no_dgi.py - [INFO] - best_hit10: 0.53558
2023-07-01 23:45:38,270 - run_wn18rr_no_dgi.py - [INFO] - 


state['optimizer']: dict_keys(['state', 'param_groups'])
2023-07-01 23:45:40,001 - run_wn18rr_no_dgi.py - [INFO] - 测试:
2023-07-01 23:45:40,001 - run_wn18rr_no_dgi.py - [INFO] - Test_mrr: 0.46145
2023-07-01 23:45:40,002 - run_wn18rr_no_dgi.py - [INFO] - Test_mr: 4263.47878
2023-07-01 23:45:40,002 - run_wn18rr_no_dgi.py - [INFO] - Test_hit1: 0.42119
2023-07-01 23:45:40,002 - run_wn18rr_no_dgi.py - [INFO] - Test_hit3: 0.47958
2023-07-01 23:45:40,002 - run_wn18rr_no_dgi.py - [INFO] - Test_hit10: 0.53558
2023-07-01 23:45:40,002 - run_wn18rr_no_dgi.py - [INFO] - 程序终止时间:Sat Jul  1 23:45:40 2023
file name: LP_ChangeLR-UnitVec-BN-CLoss-part-sample-Tem1.0_notext_conve_contrastive_loss_WN18RR_CLcmgat_27_06_2023_15_39_23



测试相似性度量函数 transe,distmult,complex,simplex

在节点17上

tmux a -t cmgat1 transe 
CUDA_VISIBLE_DEVICES=0 torchrun --rdzv_backend c10d --rdzv_endpoint localhost:0 --nnodes 1 --nproc_per_node 1 --rdzv_id 1 run_wn18rr_no_dgi.py --dataset WN18RR --loss_function contrastive_loss --use_test 1 --test_name  ReLU6-transe --score_func transe --subgraph_loss_rate 0.0 --sample_mod part --temperature 0.2 --stop_num 50 --change_lr 0 --optimizer adam  --Q 1.0 



tmux a -t cmgat3 distmult
CUDA_VISIBLE_DEVICES=2 torchrun --rdzv_backend c10d --rdzv_endpoint localhost:0 --nnodes 1 --nproc_per_node 1 --rdzv_id 1 run_wn18rr_no_dgi.py --dataset WN18RR --loss_function contrastive_loss --use_test 1 --test_name  ReLU6-distmult --score_func distmult --subgraph_loss_rate 0.0 --sample_mod part --temperature 0.2 --stop_num 50 --change_lr 0 --optimizer adam  --Q 1.0 